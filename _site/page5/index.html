<!DOCTYPE html>
<html lang="zh-cn">
    <head>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="author" content="jgj" />
        <meta name="viewport" content="width=device-width" /> 
        <title>记录生活工作中的点滴 | 我是疯子</title>
        

        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <!-- bootstrap source -->
        <!-- 新 Bootstrap 核心 CSS 文件 -->
        <link rel="stylesheet" href="http://cdn.bootcss.com/bootstrap/3.2.0/css/bootstrap.min.css" />
        <!-- 可选的Bootstrap主题文件（一般不用引入） -->
        <link rel="stylesheet" href="http://cdn.bootcss.com/bootstrap/3.2.0/css/bootstrap-theme.min.css" />
        <!-- jQuery文件。务必在bootstrap.min.js 之前引入 -->
        <script src="http://cdn.bootcss.com/jquery/1.11.1/jquery.min.js"></script>
        <!-- 最新的 Bootstrap 核心 JavaScript 文件 -->
        <script src="http://cdn.bootcss.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>

        <link rel="stylesheet" href="/asset/css/kissdata.css" />

        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="http://cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"></script>
            <script src="http://cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <link href="/feed.html" rel="alternate" title="jgj" type="application/atom+xml" />
        <link rel="shortcut icon" href="/favicon.ico" />
        <link rel="icon" href="/favicon.ico" />

        <style type="text/css">
            body {
                padding-top: 55px;
                padding-bottom: 30px;
                background-color: #EEE;
            }
        </style>

        <link rel="stylesheet" href="/asset/js/google-code-prettify/prettify.css">
        <script src="/asset/js/google-code-prettify/prettify.js"></script>

        <script type="text/javascript">
            $(document).ready(function () {

                // go to top
                var bt = $('#toolBackTop'); var sw = $(document.body)[0].clientWidth; var limitsw = (sw - 840) / 2 - 80; if (limitsw > 0){ limitsw = parseInt(limitsw); bt.css("right",limitsw); } $(window).scroll(function() { var st = $(window).scrollTop(); if(st > 30){ bt.show(); }else{ bt.hide(); } });

                // google-code-prettify
                $("pre").addClass("prettyprint linenums"); prettyPrint();

            })
        </script>

        <!-- kp747 
        
        -->
    </head>
    <body>
            <div id="header">
    <!-- Fixed navbar -->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand normal-a" href="javascript:void(0)" onclick="javascript:void(0)">
                    <span id="site_name">我是疯子</span>
                </a>
            </div>

            <div id="navbar" class="navbar-collapse collapse">
                <ul class="nav navbar-nav">
                    <li><a href="/">首页</a></li>
                    <li><a href="/categories.html">分类</a></li>
                    <li><a href="/guestbook.html">留言</a></li>
                    <li><a href="/about.html">关于</a></li>
                    <li><a href="/feed.html">RSS</a></li>
                    <li><a href="javascript:void(0)" class="normal-a" onclick="javascript:void(0)"><span id="site_description">在此停留片刻，偶有所得！</span></a></li>
                </ul>
            </div><!--/.nav-collapse -->
        </div>
    </nav>
</div>


            <div class="container">
                <div class="row">
                    <div class="col-md-9" id="main-left">
                        <h1>记录生活工作中的点滴</h1>

<hr class="small-margin" />

<div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/24/hadoop%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0.html"><span class="title">Hadoop运维相关笔记</span></a><span class="date">2014-12-24</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#datanode">datanode无法停止</a></li>
  <li><a href="#bad-connect">Bad connect</a></li>
  <li><a href="#section">配置优化</a></li>
  <li><a href="#distcp">distcp</a></li>
</ul>

<p>Hadoop的安装，此处不做过多介绍。只是说在使用hadoop过程中一些运维的事情。</p>

<h3 id="datanode">datanode无法停止</h3>
<p>经常遇到这样情况，使用 <code>jps</code> 命令查看进程，发现 datanode 还在，但是使用命令，</p>

<pre><code>$ ./sbin/hadoop-daemon.sh stop datanode
no datanode to stop
$
</code></pre>

<p>却提示datanode进程不在， 是什么原因呢？
使用命令</p>

<pre><code>./bin/hadoop dfsadmin -report
</code></pre>

<p>可以报告各个节点的状态信息。报告中的各个节点也在，使用上面的stop命令停止节点时，仍然是提示进程不在。<br />
原来是保存 datanode.pid的文件被换了。默认的文件会在 <code>/tmp/hadoop-USER-datanode.pid</code> 中，这个时候，查看 /tmp/hadoop*会有比较多的文件。<br />
因为默认 /tmp 路径下的文件会经常被修改、删除等，所以将这些文件放在 /tmp目录不够安全，可以修改该进程号存放的路径。</p>

<pre><code>cat etc/hadoop/mapred-env.sh
...
#export HADOOP_MAPRED_PID_DIR= # The pid files are stored. /tmp by default.   export HADOOP_MAPRED_PID_DIR=/path_to/data/hdfs/pid
</code></pre>

<p>参考 <a href="http://blog.sina.com.cn/s/blog_6d932f2a0101fsxn.html" target="_blank">hadoop常见问题(2).no datanode to stop</a>。</p>

<p>什么情况会导致产生别的datanode.pid的文件呢。查看datanode的log，发现会报一些错误，导致datanode被强制或错误的关掉了。</p>

<h3 id="bad-connect">Bad connect</h3>

<p>运行mapreduce、上传、下载hadoop文件时，会提示 bad connect，如下：</p>

<pre><code>14/12/21 17:02:26 INFO hdfs.DFSClient: Exception in createBlockOutputStream
java.io.IOException: Bad connect ack with firstBadLink as 10.10.12.168:50010
</code></pre>

<p>这个和上面是同一个原因，是对应的datanode被关闭导致的。但是是什么原因导致的关闭呢？datanode日志报错:</p>

<p>发现有161上如下错误：</p>

<p>参考 <a href="http://blog.csdn.net/joomlaer/article/details/16801717" target="_blank">hadoop的datanode异常结束</a>，是因为有坏的磁盘导致的。
可在在hdfs-site.xml里屏蔽掉坏磁盘。<br />
如何检测坏的磁盘， <code>hadoop fsck /</code> 可以么？</p>

<p>参考别的资料，配置 hdfs-site.xml 中的 <code>dfs.datanode.socket.write.timeout</code>，尝试将timeout的时间调长些。</p>

<h3 id="section">配置优化</h3>
<ul>
  <li>
    <p>noatime的设置<br />
为了充分发挥性能，需要使用noatime选项挂载磁盘，表示执行读操作时，不更新文件的访问时间，可以显著提供性能。</p>
  </li>
  <li>
    <p>缓冲区大小<br />
io.file.buffer.size默认是4KB，作为hadoop缓冲区，读写hdfs的文件、map的输出都用到了这个缓冲区容量，可以设置为64KB(65536字节)或128KB(131072)(太大了map和reduce任务可能会内存溢出)。</p>
  </li>
  <li>
    <p>HDFS块大小<br />
默认大小64MB，可通过 hdfs-size.xml的dfs.block.size设为 128MB(134 217 728)或256MB(268 435 456)来降低namenode的内存压力！</p>
  </li>
  <li>
    <p>保留存储空间<br />
dfs.databide.du.reserved属性来制定待保留的空间大小（字节为单位），避免将该磁盘空间用满！</p>
  </li>
</ul>

<h3 id="distcp">distcp</h3>
<p>分布式复制, 能从hadoop的文件系统并行复制大量数据。</p>

<ul>
  <li>
    <p>src/aa 拷贝至 /dest/aa <br />
如果/dest/aa存在，则/src/aa拷贝成/dest/aa/aa; 如果/dest/aa不存在，则/src/aa拷贝成/dest/aa <br /></p>
  </li>
  <li>
    <p>/src/aa, /src/bb 拷贝至 /dest/aa <br />
无论/dest/aa存在或不存在，始终拷贝成/dest/aa/aa, /dest/aa/bb;/src/aa 更新/覆盖拷贝(-update/-overwrite) 至 /dest/aa;无论/dest/aa存在不存在，始终拷贝成/dest/aa<br /></p>
  </li>
  <li>
    <p>/src/aa, /src/bb 更新/覆盖拷贝至 /dest/aa <br />
同上，但是，如果/src/aa和/src/bb下有同名的文件，那么就会引起冲突，报错。</p>
  </li>
</ul>

</div>
        <div class="more text-right"><a href="/2014/12/24/hadoop%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/23/go%E8%AF%AD%E8%A8%80%E7%9F%A5%E8%AF%86%E7%82%B9.html"><span class="title">Go语言知识点</span></a><span class="date">2014-12-23</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">时间格式化</a></li>
  <li><a href="#vimgo">vim中go语法高亮显示</a></li>
  <li><a href="#json">json解析问题</a></li>
</ul>

<h3 id="section">时间格式化</h3>

<p>go语言提供的时间接口还是很丰富的，但是对显示时间格式化操作时，必须用 <code>2006-01-02 15:04:05</code>，这让人比较纠结</p>

<pre><code>fmt.Println(timeNow.Format("2006-01-02T15:04:05.999Z+08:00"))
fmt.Println(time.Now().Format("2006-01-02 15:04:05"))
</code></pre>

<p><a href="http://golang.org/pkg/time/" target="_blank">golang文档</a>中描述，如</p>

<pre><code>Mon Jan 2 15:04:05 MST 2006
01/02 03:04:05PM 06 -0700
</code></pre>

<p>想起了 庄晓立(Liigo)的<a href="http://blog.csdn.net/liigo/article/details/23699459" target="_blank">我为什么放弃Go语言</a>，确实还是有比较多的限制。</p>

<p>在使用时间做转换的时候，都会遇到时区的问题，比如</p>

<pre><code>the_time, _ := time.Parse("2006-01-02T15:04:05", "2015-06-16T15:19:41")
fmt.Println("%d", the_time.Unix())
</code></pre>

<p>返回结果为 <code>1434467981</code>，将这个结果转为对应的年月日时分秒 </p>

<pre><code>$ date -d "@1434467981"
Tue Jun 16 23:19:41 CST 2015
</code></pre>

<p>多了八个小时，这就是时区带来的问题。可在解析的时候指定时区，如下：</p>

<pre><code>loc, _ := time.LoadLocation("Local")
// loc, _ := time.LoadLocation("Asia/Shanghai")
the_time, _ := time.ParseInLocation("2006-01-02T15:04:05", "2015-06-16T15:19:41",loc)
fmt.Println("%d", the_time.Unix())
</code></pre>

<p>这个时候的返回结果为 <code>1434439181</code>，就合适了。注意，这儿使用的是函数 <code>ParseInLocation</code>。</p>

<h3 id="vimgo">vim中go语法高亮显示</h3>

<p>参考 <a href="http://www.tuicool.com/articles/nmqaMbq" target="_blank">vim中go的语法高亮设置</a>。过程如下</p>

<pre><code>sudo cp -r $GOROOT/misc/vim/indent/* /usr/share/vim/vimcurrent/indent
sudo cp -r $GOROOT/misc/vim/syntax/* /usr/share/vim/vimcurrent/syntax
sudo cp -r $GOROOT/misc/vim/compiler/* /usr/share/vim/vimcurrent/compiler
sudo cp -r $GOROOT/misc/vim/ftplugin/* /usr/share/vim/vimcurrent/ftplugin
sudo cp -r $GOROOT/misc/vim/ftdetect /usr/share/vim/vimcurrent/
</code></pre>

<p>in some case, vimrc should set the filetype</p>

<pre><code>au BufRead,BufNewFile *.go set filetype=go
</code></pre>

<h3 id="json">json解析问题</h3>

<p>如下的场景应该是比较熟悉的json解析方式</p>

<pre><code>type Book struct {
    Title   string
    Author  string
}
b := [] byte('{"Title": "go", "Author": "jgj"}')
var book Book
err := json.Unmarshal(b, &amp;book)
</code></pre>

<p>这样就将json中的内容填充到了额book变量中，期间的匹配解析过程就不多介绍。有个问题，如果字符串中的key是 “_title” 或者 “1” ，那如果处理呢。<br />
要知道，go中要使用大写才是public的，这种情况下，可以如下表示</p>

<pre><code>    type Book struct {
    Title   string `json:"_title"`
    Author  string
}
</code></pre>

<p>即使用<code>json:"xxx"</code>的方式指定匹配那个key，这种方式可以使用与各种情况。       </p>

</div>
        <div class="more text-right"><a href="/2014/12/23/go%E8%AF%AD%E8%A8%80%E7%9F%A5%E8%AF%86%E7%82%B9.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/17/Linux-shell.html"><span class="title">Linux Shell</span></a><span class="date">2014-12-17</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">文件重命名</a></li>
  <li><a href="#section-1">文件内容修改</a></li>
  <li><a href="#xx">删除比xx更新的文件</a></li>
  <li><a href="#shell">Shell中一些单引号</a></li>
  <li><a href="#section-2">正则表达式反向引用</a></li>
  <li><a href="#section-3">一些指定的文件大小和</a></li>
  <li><a href="#scp">打包scp操作</a></li>
  <li><a href="#sed">sed拆分</a></li>
  <li><a href="#section-4">获取字符串长度</a></li>
  <li><a href="#ip">增加虚拟ip</a></li>
  <li><a href="#awk-">awk 输出时改变分隔符</a></li>
  <li><a href="#grep">grep的正则表达式</a></li>
  <li><a href="#awk--1">awk 几个例子</a></li>
  <li><a href="#grep-ascii">grep 非ascii</a></li>
  <li><a href="#bzip2--d">bzip2 -d文件失败的修复</a></li>
  <li><a href="#grep-1">grep两个关键字做去重</a></li>
  <li><a href="#if-grep-">非常有用的”if-grep” 结构</a></li>
  <li><a href="#section-5">控制字符</a></li>
</ul>

<blockquote>
  <p>本文记录在实际工作中用到的一些Bash Shell，可能比较偏门，但是方便以后使用</p>
</blockquote>

<h3 id="section">文件重命名</h3>

<p>参考 <a href="http://snailwarrior.blog.51cto.com/680306/139706" target="_blank">Linux批量重命名文件 </a>。<br />
我想把它们的名字的第一个1个字母变为”q”，其它的不变： </p>

<pre><code>for i in `ls`; do mv -f $i `echo $i | sed 's/^./q/'`; done
</code></pre>

<p>修改前面5个字母为zhaozh：</p>

<pre><code>for i in `ls`; do mv -f $i `echo $i | sed 's/^...../zhaozh/'`; done
</code></pre>

<p>修改后面5个字母为snail：</p>

<pre><code>for i in `ls`; do mv -f $i `echo $i | sed 's/.....$/snail/'`; done
</code></pre>

<p>在前面添加 <em>hoho</em>：</p>

<pre><code>for i in `ls`; do mv -f $i `echo "_hoho_"$i`; done
</code></pre>

<p>所有的小写字母变大写字母：</p>

<pre><code>for i in `ls`; do mv -f $i `echo $i | tr a-z A-Z`; done
</code></pre>

<p>多层目录下的文件，将TC开头的文件换乘MJ</p>

<pre><code>for i in `find ./ -name TC*`; do mv -f $i `echo $i | sed 's/\/TC/\/MJ/'`; done
</code></pre>

<p>将done改为update</p>

<pre><code>for i in `find ./ -name done`; do mv $i `echo $i | sed 's/done/update/'` ; done
</code></pre>

<h3 id="section-1">文件内容修改</h3>

<p>第一种比较笨的办法，是将修改后的内容存到另一文件中，然后替换</p>

<pre><code>for i in `find ./ -type f`; do cat $i |  sed -e "s/AAAA/BBBBB/g" -e "s/CCCCC/DDDDD/g" &gt; bak ; mv bak $i; done
</code></pre>

<p>也可以直接用 <code>sed -i</code> 命令  </p>

<h3 id="xx">删除比xx更新的文件</h3>

<pre><code>for i in `find ./ \! -newer 1390534720.snapshot ` ; do rm $i ; done   ##older with \! -newer
</code></pre>

<p>find用户 -prune是除去这个目录</p>

<h3 id="shell">Shell中一些单引号</h3>

<p>sed中单引号</p>

<pre><code>echo "dds'fa" | sed -e "s#'##g"
</code></pre>

<p>awk中单引号</p>

<pre><code>echo "ddd'fs" | awk -F"'" '{print $1}'
</code></pre>

<p>awk打印单引号</p>

<pre><code>echo "ddd'fs" | awk -F"'" '{printf("%s \047 \n",$1) }'
</code></pre>

<h3 id="section-2">正则表达式反向引用</h3>

<p>在前面匹配的时候，一定要用()表示出来</p>

<pre><code>echo "optional string v = 1;" | sed -n -r 's/optional (int32|int64) (.*)/optional \1 \2 \/\/ \1  /p'
</code></pre>

<p>vim中的()要用反斜线 </p>

<pre><code>:'&lt;,'&gt;s/get_\(.*\);/get_\1() { return \1; }/g        
:'&lt;,'&gt;s/set_\(.*\);/set_\1(int m_\1) { this-&gt;\1 = m_\1; }/g
:%s/ok|\([0-9]\)|\([0-9.]*\)/ok|\1,price|\2,imei/g
</code></pre>

<h3 id="section-3">一些指定的文件大小和</h3>

<pre><code>du -sh 21_20131001* | awk -F'M' '{sum+=$1} END {print sum}'
</code></pre>

<p>这儿使用M做awk的分隔符</p>

<h3 id="scp">打包scp操作</h3>

<p>参考 <a href="http://www.thingy-ma-jig.co.uk/blog/03-09-2008/using-tar-and-ssh-improve-scp-speeds" target="_blank">ssh tar</a>  </p>

<pre><code>(cd /lib/modules; tar zcvf - 2.6.19 ) | ssh -p 60001 root@192.168.0.254 tar zxvf - -C /lib/modules/
ssh 192.168.1.2 -T -c arcfour -o Compression=no -x "tar cf - /remote/path" | tar xf - -C .
ssh -p 60020 work@ck -T -c arcfour -o Compression=no -x "cd /home/work/pb/base_pb/201311/; tar cf - 06" | tar xf - -C .
tar czf - www.example.com/ | ssh joebloggs@otherserver.com tar xzf - -C ~/
</code></pre>

<p>一些说明  <br />
T: turn off pseudo-tty to decrease cpu load on destination.<br />
c: arcfour: use the weakest but fastest SSH encryption. Must specify “Ciphers arcfour” in sshd_config on destination.<br />
o: Compression=no: Turn off SSH compression.
x: turn off X forwarding if it is on by default.</p>

<h3 id="sed">sed拆分</h3>

<pre><code>sed -n '10001,10200'p stats_21log &gt; stats_11
for i in {1..11}; do start_line=`echo $i*1000-999 | bc`; end_line=`echo $i*1000 | bc`; sed -n "$start_line,${end_line}p" stats_21log &gt; stats_$i ; done
</code></pre>

<p>注意，计算时使用bc，sed中使用双引号</p>

<h3 id="section-4">获取字符串长度</h3>

<pre><code>log_path_len=`expr length $log_path`
datetime_path=${log_dir:${log_path_len}:50}  
</code></pre>

<p>后者可以将字符串后面的字段获取到， log_dir开头的内容时log_path  </p>

<h3 id="ip">增加虚拟ip</h3>

<pre><code>ifconfig eth0:1 192.168.100.11 netmask 255.255.255.0
ifconfig eth0:2 192.168.100.12 netmask 255.255.255.0
</code></pre>

<h3 id="awk-">awk 输出时改变分隔符</h3>

<pre><code>echo "ab cd ds" | awk '{OFS=":"; $2="*";  print $0}' //如果没有$2="*" 这条，OFS=":"就不起作用
echo a b c d|awk '{OFS=":";print $1,$2,$3,$4}'    //这样也可以
echo a b c d|awk '{OFS=":";print $1 OFS $2,$3,$4}' //也可以
echo "ab:bc:d" | awk -F':'  '{print | "cut -d : -f -"(NF-1)}'      #delete the last field
</code></pre>

<p>前N个：cut -d 分隔符 -f -N
第X个：cut -d 分隔符 -f X
最后一个：awk -F 分隔符 ‘{pint $NF}’
去除最后一个：</p>

<pre><code>awk -F 分隔符 '{print | "cut -d 分隔符 -f -"(NF-1)}'
</code></pre>

<p>去除指定字段X：</p>

<pre><code>awk -F 分隔符 ’{print | "cut -d 分隔符 -f 1-(X-1),(X+1)-"(NF)}' 
</code></pre>

<h3 id="grep">grep的正则表达式</h3>

<pre><code>grep -o "device=.*&amp;" file   --- 会时贪婪搜索
grep -o "device=.*?&amp;" file  --- shell的正则中不支持？的懒惰
grep -o "device=[^&amp;]*" file --- 得到预期的到&amp;之间的数据
</code></pre>

<h3 id="awk--1">awk 几个例子</h3>

<pre><code>awk '{a[$1]+=$2;}END{for(i in a){if(a[i]&gt;8){print i" "a[i];}}}' aa
cat */result_201* | awk -F' ' '{tmp=$1; $1="";gsub(/ /, "-"); val[$0]+=tmp}END{for(i in val) {print val[i]" "i};}' | sort -n -r &gt; total 
</code></pre>

<p>多个文件中包含设备类型及个数，合并求和 (大写转为小写)</p>

<pre><code>cat *_201406 | tr "[:upper:]" "[:lower:]" | awk '{names[$2]+=$1} END {for (i in names) {print names[i] " " i} }'
</code></pre>

<h3 id="grep-ascii">grep 非ascii</h3>

<p>打印行数，并高亮显示非ascii码字符</p>

<pre><code>grep --color='auto' -P -n "[\x80-\xFF]" file.xml
</code></pre>

<h3 id="bzip2--d">bzip2 -d文件失败的修复</h3>

<pre><code>bzip2recover file.bz2
bzip2 -d rec*.bz2 &gt; file   
</code></pre>

<h3 id="grep-1">grep两个关键字做去重</h3>

<p>想要实现功能
* file_name中包含InitGame 或UserLogin的行
* 这些行中取equdid(设备id)、channel(渠道号)这两个的内容
* 对这两个内容，做去重求和</p>

<pre><code>grep  -E "InitGame|UserLogin" file_name | grep -o -E "equdid=[^:]*|channel=[^:]*" | awk '{if(NR%2==0){print $0}else{printf "%s:",$0}}' | sort | uniq | wc -l
</code></pre>

<p>说明，<code>grep -o -E</code> 可以得到两个关键字的内容，但是输出到两行中，于是用awk在一行中输出。上面的 <code>print $0</code>（而不是用printf）就换行。</p>

<h3 id="if-grep-">非常有用的”if-grep” 结构</h3>

<pre><code>if grep -q bash test.sh 
then  # in new line
    echo "find bash in test.sh"
fi
</code></pre>

<h3 id="section-5">控制字符</h3>

<pre><code>Ctl-B  光标后退,这应该依赖于bash输入的风格
Ctl-H  backspace,删除光标前边的字符
Ctl-I  就是tab键
Ctl-J  新行
Ctl-L  clear,清屏
Ctl-M  回车
Ctl-Q  继续(等价于XON字符),这个继续的标准输入在一个终端里
Ctl-S  挂起(等价于XOFF字符),这个被挂起的stdin在一个终端里,用Ctl-Q恢复
Ctl-U  删除光标到行首的所有字符,在某些设置下,删除全行. 
Ctl-V  当输入字符时,Ctl-V允许插入控制字符.比如,下边2个例子是等价的
        echo -e '\x0a' 
        echo &lt;Ctl-V&gt;&lt;Ctl-J&gt; 
        Ctl-V 在文本编辑器中十分有用,在vim中一样. 
Ctl-W  删除当前光标到前边的最近一个空格之间的字符. 
       在某些设置下,删除到第一个非字母或数字的字符. 
Ctl-Z  终止前台工作. 
</code></pre>

</div>
        <div class="more text-right"><a href="/2014/12/17/Linux-shell.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/12/go%E6%93%8D%E4%BD%9Cmysql-memcache-mongodb.html"><span class="title">Go操作mysql Memcache Mongodb</span></a><span class="date">2014-12-12</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#mysql">操作mysql</a></li>
</ul>

<blockquote>
  <p>发现go提供的操作msyql、memcache、mongodb的文档没有lua-ngx的好读，即实例不是很明确，此文列出自己操作时的实例，可让快速入手，但是优化以及错误处理等还有很多工作。</p>
</blockquote>

<h3 id="mysql">操作mysql</h3>

<p><a href="https://github.com/go-sql-driver/mysql/wiki/Examples" target="_blank">go-sql-driver/mysql Example</a> 上提供了用go操作mysql的两个例子。
例子中关于查询，一个是一次只取一个结果，一个是一次去多个结果，而且使用了prepare的方法，防止sql注入攻击。<br />
此文中是参考上面例子，做的测试。</p>

<p>只取一个数据的例子</p>

<pre><code>import (
    "database/sql"
    _ "github.com/go-sql-driver/mysql"
)

func main() {
    db, err := sql.Open("mysql", "user:passwd@tcp(host:port)/db_name")
    if err != nil {
        panic(err.Error())
    }
    defer db.Close()

    stmtOut, err := db.Prepare("SELECT uid FROM mj_table limit 1")
    if err != nil {
        panic(err.Error())
    }
    var uid string
    err = stmtOut.QueryRow().Scan(&amp;uid)
    if err != nil {
        Log.Info("err to Scan: %s", err)
        return
    }
    Log.Info("uid: %s", uid)
}
</code></pre>

<p>取多个数据的例子</p>

<pre><code>...
rows, err := db.Query("select appid from mj_table limit 1")
if err != nil {
    Log.Info("No Err in select msyql: %s", err)
    return
}   
// Get column names
columns, err := rows.Columns()
if err != nil {
    panic(err.Error()) 
}   

// Make a slice for the values
values := make([]sql.RawBytes, len(columns))
scanArgs := make([]interface{}, len(values))   // 必须要有此类型
for i := range values {
    scanArgs[i] = &amp;values[i]
}

// Fetch rows
for rows.Next() {
    // get RawBytes from data
    err = rows.Scan(scanArgs...)
    if err != nil {
        panic(err.Error()) 
    }
    var value string
    for i, col := range values {
        if col == nil {
            value = "NULL"
        } else {
           value = string(col)
        }
        Log.Info("name: %s, value: %s ", columns[i], value)
    }
    Log.Info("-----------------------------------")
}
...
</code></pre>

</div>
        <div class="more text-right"><a href="/2014/12/12/go%E6%93%8D%E4%BD%9Cmysql-memcache-mongodb.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/09/Heka%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0.html"><span class="title">Heka使用学习</span></a><span class="date">2014-12-09</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">简介</a>    <ul>
      <li><a href="#section-1">描述</a></li>
      <li><a href="#section-2">架构</a></li>
    </ul>
  </li>
  <li><a href="#section-3">安装</a>    <ul>
      <li><a href="#heka">安装Heka环境</a></li>
      <li><a href="#section-4">添加插件</a></li>
    </ul>
  </li>
  <li><a href="#section-5">使用</a>    <ul>
      <li><a href="#heka-1">配置heka</a></li>
      <li><a href="#section-6">运行</a></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>统计分析时，难免有实时统计、以及日志的转移分发，crontab、scp等可以实现该功能，但是难免显得粗糙且维护比较复杂，而 Heka 可胜任此工作。当然，Heka不只是如此简单的功能。</p>
</blockquote>

<h2 id="section">简介</h2>

<p>Heka是一款拥有数据收集、分析、监视和报表的工具，Mozilla Service团队提供的开源项目，截止到现在，版本已经到 0.9.0。
<a href="https://hekad.readthedocs.org/en/latest" target="_blank">Heka的官方文档</a>有详细和权威的说明，本篇只是记录下使用过程中，觉得有所帮助的东西，能更加快速的认识Heka。</p>

<h3 id="section-1">描述</h3>
<p>Heka使用Go语言编写，内部对数据的过滤、转发等，都是采用指针形式，可支撑 10Gb/s 的消息数据（网上说法，自己没有实际测过！）。
目前heka可以支持多种格式的消息，官网上介绍的有：</p>

<pre><code>AMQP
Docker
FilePolling
Http
HttpListen
Kafka
Logstreamer
Process
ProcessDirectory
StatAccum
Statsd
Tcp
Udp
</code></pre>

<p>对于这些格式的消息，官方提供的处理方式可满足大部分的需求；若不满足需求，可以自行扩展或开发插件。关于插件的开发流程在下面章节介绍。<br />
Heka配置文件采用 <a href="https://github.com/toml-lang/toml" target="_blank">.toml 格式</a>。</p>

<h3 id="section-2">架构</h3>

<p>一般而言Heka中的数据流要经过5个过程，即</p>

<pre><code>Inputs
Decoders
Filters
Encoders
Outputs
</code></pre>

<p>从这几步的命名中，可以大体知道每步实现的功能。当然这5步不是必须都要有的，如果接受到的数据，没有加密或其他特殊格式，可以直接处理，那Decoders就不需要。
甚至，不想输出任何东西，不提供Outputs都可以，但是这样一来就没有了实际意义。<br />
PS：在Hekad实际处理时，当数据处理完成之后，要执行类似 <code>pack.Recycle()</code> 的操作，来释放所持有的空间，做资源的循环再利用。</p>

<h2 id="section-3">安装</h2>

<p>安装编译heka环境的过程还算比较简单，但是要下载一些网络库，这个过程需要翻墙，是个比较<strong>烦心</strong>的事。<br />
本文使用 <a href="https://github.com/goagent/goagent" target="_blank">goagent</a>翻墙，代理为 127.0.0.1:8087</p>

<h3 id="heka">安装Heka环境</h3>

<pre><code>$ export http_proxy="http://127.0.0.1:8087"
$ git clone https://github.com/mozilla-services/heka
$ cd heka
$ source build.sh  #这个过程会下载一些依赖库，并生成build目录
  
$ ctest &amp;&amp; make ctest  # 做编译测试
</code></pre>

<h3 id="section-4">添加插件</h3>

<p>Heka中真正强大的一点也就在于能通过插件扩展功能，支持各种需求。本篇不介绍插件如何实现，以及插件中的代码结构等问题，因为目前了解的还不够深，介绍的可能也会有偏差，只是介绍下插件如何编译与生效。 </p>

<p>假设我们要实现一个 hello_world 的插件，将插件的代码放在 <code>heka/externals/hello_world</code>目录下。有了这样的一个目录，我们在配置文件中指明。配置文件是cmake目录下 <code>plugin_loader.cmake</code>，
刚clone下来的heka，没有这个配置文件，手工创建一个。</p>

<pre><code>$ cat cmake/plugin_loader.cmake
add_external_plugin(svn https://url_to/heka_plugins/hello_world:local)
</code></pre>

<p>说明，heka的插件会先在本地找插件，如果没有，则根据url的地址去下载；url来源可以是git、svn或hg。<br />
完成插件的开发，并做好配置之后，就可以重新编译可执行文件</p>

<pre><code>$ cd heka
$ source build.sh
$ cpack
</code></pre>

<p>这样，在build目录下，就会有编译好的支持新插件的可执行文件。 </p>

<h2 id="section-5">使用</h2>

<p>上面编译好的build目录下，有压缩打包文件 <code>heka-0_9_0-linux-amd64.tar.gz</code>，里面即包含有运行所需要的二进制文件。
运行Heka时，需要提供配置文件，假设目录为 <code>conf/hekad.toml</code>。</p>

<h3 id="heka-1">配置heka</h3>
<p>heka的配置文件要设置好所需要的 Input/Decoder/Filter/Encoder/Output，（没有用的可以不配置），也提供整个heka所需要的全局的配置，此处提供一个简单的配置如下：</p>

<pre><code>[hekad]
cpuprof = "log/cpuprof.log"    #
memprof = "log/memprof.log"    # heka运行时cpu、mem出错的日志
maxprocs = 24
base_dir = "base_dir"
pid_file = "hekad.pid"

[LogstreamerInput]
log_directory = "/opt/nginx/logs"  # 指定input的来源，使用的是 LogstreamerInput 类型的插件
file_match = 'access\.log'         # 文件，注意，此处使用的是单引号

[PayloadEncoder]
append_newlines = false

[LogOutput]
message_matcher = "TRUE"
encoder = "PayloadEncoder"
</code></pre>

<p>可用<code>message_matcher</code>来设定各种的匹配规则，个人理解，他可以实现Filter的功能，而因为功能比较简单，就合并到Output中了。
更多的配置参考 <a href="https://hekad.readthedocs.org/en/latest/config/index.html" target="_blank">Configuring hekad</a>。</p>

<h3 id="section-6">运行</h3>

<p>提供配置所需要的目录，如log，base_dir, 使用命令启动</p>

<pre><code>./bin/hekad -config=./conf/hekad.toml
</code></pre>

<p>如果是使用上面的配置，heka会将 <code>/opt/nginx/logs/access.log</code> 在屏幕中输出，并且，每当access.log中增加一行，屏幕就会实时输出这么一行！</p>

<p>Heka中有提供了其他的数据流处理，可以多尝试使用。:)</p>

</div>
        <div class="more text-right"><a href="/2014/12/09/Heka%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/06/lex-yacc-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html"><span class="title">Lex Yacc 学习笔记</span></a><span class="date">2014-12-06</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">简介</a>    <ul>
      <li><a href="#section-1">编译工具</a></li>
    </ul>
  </li>
  <li><a href="#lex">lex</a>    <ul>
      <li><a href="#section-2">框架</a></li>
      <li><a href="#section-3">简单实例1</a></li>
      <li><a href="#section-4">简单实例2</a></li>
    </ul>
  </li>
  <li><a href="#yacc">yacc</a>    <ul>
      <li><a href="#section-5">框架</a></li>
      <li><a href="#section-6">简单实例1</a></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>项目开始时，要提供sql语句的查询功能，而后台的实现不是常规sql，计划实现个简单的sql功能，于是看到了lex、yacc</p>
</blockquote>

<h2 id="section">简介</h2>

<p>lex/yacc多用于编译器的开发，lex做词法解析，yacc做语法解析。可以看看 <a href="http://dinosaur.compilertools.net/" target="_blank">The LEX &amp; YACC Page</a>
 和 <a href="http://epaperpress.com/lexandyacc/index.html" target="_blank">Lex &amp; Yacc Tutorial</a> 。历史来源、理论等不做过多说明。</p>

<h3 id="section-1">编译工具</h3>
<p>学习过程中，尝试在Linux上使用C语言的工具，lex使用工具 <code>flex</code>， yacc使用工具 <code>bison</code>。假设有文件 frame.l (lex文件) 和frame.y(yacc文件)，大致编译如下</p>

<pre><code>$ flex frame.l  #生成lex.yy.c
$ bison frame.y #生成frame.tab.c和frame.tab.h
$ gcc frame.tab.c lex.yy.c -o start
</code></pre>

<h2 id="lex">lex</h2>

<h3 id="section-2">框架</h3>
<p>lex代码框架形式如下</p>

<pre><code>... 定义  ... 
%%     
... 规则  ... 
%% 
... 子程序  ...
</code></pre>

<p>通过 <code>%%</code> 将lex分为三部分。</p>

<h3 id="section-3">简单实例1</h3>
<p>lex中可以通过正则表达式做匹配（对于正则表达式，此文不描述），结合其框架，我们先实现一个简单的实例，打印 是数字 还是 单词。
本实例来自 <a href="http://blog.csdn.net/djinglan/article/details/9263361" target="_blank">Lex和Yacc入门</a>（其源出处已经404了，此处只好提供一个转发的地址了）</p>

<pre><code>%{
    #include &lt;stdio.h&gt;
%}

%%
[0123456789]+           printf(“NUMBER\n”);
[a-zA-Z][a-zA-Z0-9]*    printf(“word\n”);
</code></pre>

<p>上面定义处引用 <code>stdio.h</code>是为了使用里面的printf函数。注意这儿实现C功能的解析，所以该有 <code>;</code> 的地方还是不能少。假设文件名为 “print.l”，可以用如下命令编译，执行</p>

<pre><code>$ flex print.l
$ gcc lex.yy.c -o print -ll
$ ./print
daa
Word

fadfadfafasddfasdfadsf
Word

234
NUMBER

dfa234
Word 
</code></pre>

<p>-ll表示连接lex的库，在liblex中有main函数，所以上面print.l中没有main函数的情况下，还是可以运行。</p>

<h3 id="section-4">简单实例2</h3>
<p>上面的例子给出一个可以运行的的代码，先建立了使用的信心；<a href="http://epaperpress.com/lexandyacc/prl.html" target="_blank">lex/yacc的epp</a>上提供的一个实例能很好的描述lex的一些内在逻辑，如下：</p>

<pre><code>%{
    int nchar, nword, nline;
%}
%%
\n         { nline++; nchar++; }
[^ \t\n]+  { nword++, nchar += yyleng; }
.          { nchar++; }
%%
int main(void) {
    yylex();
    printf("%d\t%d\t%d\n", nchar, nword, nline);
    return 0;
}
</code></pre>

<p>此处代码使用lex中预定义的变量：</p>

<pre><code>int yylex(void)     调用扫描器,返回标记 
char *yytext        指针,指向所匹配的字符串 
yyleng              所匹配的字符串的长度 
yylval              与标记相对应的值 
int yywrap(void)    约束,如果返回 1 表示扫描完成后程序就结束了,否则返回 0 
FILE *yyout         输出文件 
FILE *yyin          输入文件 
INITIAL             初始化开始环境 
BEGIN               按条件转换开始环境 
ECHO                输出所匹配的字符串
</code></pre>

<h2 id="yacc">yacc</h2>

<h3 id="section-5">框架</h3>
<p>yacc代码框架形式如下</p>

<pre><code>... 定义  ... 
%%     
... 规则  ... 
%% 
... 子程序  ... 
</code></pre>

<p>可以发现，yacc和lex的架构是一样的。YACC可以解析输入流中的标识符(token)，而这些标识符来自lex。</p>

<h3 id="section-6">简单实例1</h3>

<p>假设有lex文件，其内容为：</p>

<pre><code>%{
    #include &lt;stdio.h&gt;
    #include "y.tab.h"
%}

%%
[0-9]+                  return NUMBER;
[a-zA-Z][a-zA-Z0-9]+    return WORD;
%%
</code></pre>

<p>yacc文件中的代码：</p>

<pre><code>%{
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;

void yyerror(char *s) { 
    printf("%s\n", s); 
}   

int yywrap() {
    return  1;  
}   

int main() {
    yyparse();
    return 0;
}   
%}
%token  NUMBER WORD

%%
commands: /* empty */
    | commands command
    ;

command: target_word
    | target_num
    ;

target_word:
WORD {
    printf("\t yacc get word \n");
}
;

target_num:
NUMBER {
    printf("\tyacc get number\n");
}
;
%%
</code></pre>

<p>编译执行测试：</p>

<pre><code>$ flex frame.l 
$ bison -d y.y 
$ gcc lex.yy.c y.tab.c -o test 
$ ./test
wdafs
    yacc get word 

1234
    yacc get number

dsfad134
    yacc get word 
</code></pre>

<p>lex通过正则匹配得到 <code>NUMBER</code> 和 <code>WORD</code>，在yacc中使用 <code>巴科斯范式</code>得到 NUMBER 和  WORD 并做处理。本实例只是一个非常简单的例子，得到后做一个打印输出，表明我得到了什么。</p>

<p><strong>后续，其他的几个yacc的实例，并对lex和yacc做一总结</strong></p>

</div>
        <div class="more text-right"><a href="/2014/12/06/lex-yacc-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/03/zabbix%E9%97%AE%E9%A2%98.html"><span class="title">Zabbix问题</span></a><span class="date">2014-12-03</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">修改模板</a></li>
  <li><a href="#hostname">修改hostname</a></li>
  <li><a href="#serveractive">去掉ServerActive</a></li>
  <li><a href="#section-1">大体流程</a></li>
</ul>

<blockquote>
  <p>zabbix监控告警，Agent on host [] unreached for 5 minutes，尝试使用了几种方式均没有成功。后来索性将这个给关掉了，这个记录下做过的尝试，或许对以后有多帮助</p>
</blockquote>

<h3 id="section">修改模板</h3>

<pre><code>组态
 Template(模板)
   Template App Zabbix Agent
     触发器
        Zabbix agent on {HOST.NAME} is unreachable for 5 minutes
</code></pre>

<p>将表达式做修改，<code>nodata</code> 改为 <code>min</code>，即
    {Template App Zabbix Agent:agent.ping.nodata(5m)}=1
    -&gt;
    {Template App Zabbix Agent:agent.ping.min(5m)}=1</p>

<h3 id="hostname">修改hostname</h3>

<p>网上的很多资料都说将hostname和zabbix配置中的host保持一致，依照这些说明做调整，也是不生效。 <br />
说明下，该监控项以前是很正常工作的，晚上时候dns服务出现问题，导致告警，待把dns服务启动后，zabbix server和agentd都重启了，仍然有这个告警。</p>

<h3 id="serveractive">去掉ServerActive</h3>

<p>关闭掉<code>zabbix_agentd.conf</code>中指明的 <code>zabbix_agentd.conf</code></p>

<p>尝试了这么几种办法，都不生效，暂时木有找到办法！</p>

<h2 id="section-1">大体流程</h2>

<p>最近遇到了一个问题：server端使用的dns服务出现了问题，导致告警的邮件短信没有及时发送出去，后来将dns问题修复后，监控的已经没有问题了，却在很疯狂的发送短信。什么原因呢，梳理了一下监控的流程：</p>

<p>监控的类型比较多，这里只说我们要用的这种形式。zabbix server根据配置的情况（存在mysql中），定期的扫描要监控的服务，当发现有需要告警时，会根据配置信息，调用告警的脚本（或语句），并且做一记录(存放alerts表)。因为server的网络有问题，告警未能及时发送出去，Linux系统层将这些任务存放在 /var/spool/mail/zabbix列表中。好了，当zabbix服务启动后，系统识别到有zabbix用户在使用了，于是就开始执行未尽的任务 – 发短信、邮件了。删除 /var/spool/mail/zabbix 后就好了。</p>

</div>
        <div class="more text-right"><a href="/2014/12/03/zabbix%E9%97%AE%E9%A2%98.html">继续阅读全文</a></div>
    </div>
    
    <div class="post-card">
        <div class="head"><a href="/2014/12/01/%E4%BB%98%E8%B4%B9%E6%8E%A5%E5%8F%A3%E6%B5%81%E7%A8%8B.html"><span class="title">付费接口流程</span></a><span class="date">2014-12-01</span></div>
        <div class="content"><ul id="markdown-toc">
  <li><a href="#section">要求</a></li>
  <li><a href="#section-1">流程</a></li>
  <li><a href="#section-2">自身情况</a></li>
</ul>

<blockquote>
  <p>需要实现一个功能接口，调用银联或者支付宝等来给自己的服务充值。只要牵扯到钱，对安全性、一致性就要有比较苛刻的要求了，那付费接口的流程又应该是什么样子的呢？</p>
</blockquote>

<h3 id="section">要求</h3>

<ol>
  <li>
    <p>付费过程即使被别人截获，也不能有什么损失，这个过程就需要加密。能正确的调用到支付服务商（银联、支付宝）后，就由服务商来保证安全</p>
  </li>
  <li>
    <p>在没有收到支付服务商告知付费成功之前，我们就认为付费没有成功；而在收到通知之后，我方应该给服务商反馈，告知已经收到。而服务商为保证成功支付这个事件能通知到我们，也需要我方的一个反馈，没有没有收到这个反馈，会尝试多发几次</p>
  </li>
  <li>
    <p>因为一些网络延迟等，所以我方可能会收到多条支付成功的通知，对此，我方就需要能做好去重</p>
  </li>
</ol>

<h3 id="section-1">流程</h3>

<p>有些以上的想法，大体就可以整理出付费接口的一个流程。参考 Agent`K 的 <a href="http://www.cnblogs.com/agent-k/archive/2012/08/13/2636185.html" target="_blank">手机网游开发指南-付费接口</a>，虽然是移动终端的付费，但可以管中窥豹，确切的知道流程</p>

<ol>
  <li>
    <p>向支付提供商发起充值请求。</p>

    <p>如果是手机端的，请求可能要先得到用户的账号和密码；但大部分是直接访问api，进入到提供商自己的界面上。</p>

    <p>这种请求有指定API，一般为发起http请求，post方式发送指定格式的数据。出于安全考虑，这些数据需要进行加密、签名，支付商会提供一些编号、密钥之类的信息，并要求在加密、签名过程中使用。请求返回结果称为“充值申请”结果，并不是最终的充值结果。</p>
  </li>
  <li>
    <p>等待充值提供商的通知。</p>

    <p>通知方式为，回调我方指定的http地址（可能会被要求必须是80端口）。这个地址可以在提供商的后台指定，也可以在发起充值请求的参数中指定（个人认为，大多数的应该是在参数中指定回调地址）。</p>
  </li>
  <li>
    <p>收到通知后续操作</p>

    <p>进行解密、签名验证以及其他后续操作，最后按指定格式响应接收通知成功或失败。</p>

    <p>注意，可能需要做相应的去重处理。</p>
  </li>
</ol>

<h3 id="section-2">自身情况</h3>

<p>系统先实现简单功能，先没有直接充值，计划先用金币来代替：当某项服务或模块需要付费时扣除金币即可，当金币不足时，再由充值系统来购买金币。
在这样一个系统中，各个模块和金币系统都在同一个网络或同一机器上，且消费金币只是简单的修改数据库，所以就没有必要在通过回调等机制来实现！</p>

</div>
        <div class="more text-right"><a href="/2014/12/01/%E4%BB%98%E8%B4%B9%E6%8E%A5%E5%8F%A3%E6%B5%81%E7%A8%8B.html">继续阅读全文</a></div>
    </div>
    
</div>

<div class="nav-post-links">
        
        <span class="newer-posts-link">
            
                <a href="/page4" title="previous page">&laquo; Newer Posts</a>
            
        </span>
        

        
        <span class="older-posts-link">
            <a href="/page6" title="next page">Older Posts &raquo;</a>
        </span>
        
</div>

                    </div>
                    <div class="col-md-3" id="main-right">
                        <div>
    <h4><strong>文章分类</strong></h4>
    <hr class="small-margin colored-hr" />
    <ul class="side-cat-ul">
        
        <li><a href="/categories.html#cat-生活随记" title="生活随记">生活随记 (3)</a></li>
        
        <li><a href="/categories.html#cat-bigdata" title="bigdata">bigdata (9)</a></li>
        
        <li><a href="/categories.html#cat-web" title="web">web (9)</a></li>
        
        <li><a href="/categories.html#cat-database" title="database">database (3)</a></li>
        
        <li><a href="/categories.html#cat-linux" title="linux">linux (10)</a></li>
        
        <li><a href="/categories.html#cat-go" title="go">go (8)</a></li>
        
        <li><a href="/categories.html#cat-运维" title="运维">运维 (3)</a></li>
        
        <li><a href="/categories.html#cat-language" title="language">language (7)</a></li>
        
        <li><a href="/categories.html#cat-tools" title="tools">tools (1)</a></li>
        
        <li><a href="/categories.html#cat-iot" title="iot">iot (5)</a></li>
        
    </ul>
</div>

<hr class="small-margin colored-hr" />

<!-- google adsense -->
<!--
<div>
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <ins class="adsbygoogle"
        style="display:inline-block;width:300px;height:600px"
        data-ad-client="ca-pub-1339945837472110"
        data-ad-slot="8220828081"></ins>
    <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
</div>
-->


                    </div>
                </div>
            </div>

            <div id="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <hr class="colored-hr" />

                <p class="text-center">
                Copyright 2014 - 2016 | Gen time&#58; 2016-04-12 01:51:47 CST

                <!-- cnzz -->
                

                </p>


            </div>
        </div>
    </div>
    <div style="display:none;" class="back-to" id="toolBackTop">
        <a title="返回顶部" onclick="window.scrollTo(0,0);return false;" href="#top" class="back-top">返回顶部</a>
    </div>

    <!-- google analytics -->
    


</div>

    </body>
</html>
