---
title:  hadoop 运维相关笔记
date: 2014-12-24 21:12:28 +0800
tags: go
- a
- b
---

* toc 
{:toc}


Hadoop的安装，此处不做过多介绍。只是说在使用hadoop过程中一些运维的事情。

### datanode无法停止
经常遇到这样情况，使用 `jps` 命令查看进程，发现 datanode 还在，但是使用命令，

    $ ./sbin/hadoop-daemon.sh stop datanode
    no datanode to stop
    $

却提示datanode进程不在， 是什么原因呢？
使用命令
    
    ./bin/hadoop dfsadmin -report
    
可以报告各个节点的状态信息。报告中的各个节点也在，使用上面的stop命令停止节点时，仍然是提示进程不在。  
原来是保存 datanode.pid的文件被换了。默认的文件会在 `/tmp/hadoop-USER-datanode.pid` 中，这个时候，查看 /tmp/hadoop*会有比较多的文件。  
因为默认 /tmp 路径下的文件会经常被修改、删除等，所以将这些文件放在 /tmp目录不够安全，可以修改该进程号存放的路径。

    cat etc/hadoop/mapred-env.sh
    ...
    #export HADOOP_MAPRED_PID_DIR= # The pid files are stored. /tmp by default.
  export HADOOP_MAPRED_PID_DIR=/path_to/data/hdfs/pid
  
参考 [hadoop常见问题(2).no datanode to stop](http://blog.sina.com.cn/s/blog_6d932f2a0101fsxn.html){:target="_blank"}。

什么情况会导致产生别的datanode.pid的文件呢。查看datanode的log，发现会报一些错误，导致datanode被强制或错误的关掉了。

### Bad connect 

运行mapreduce、上传、下载hadoop文件时，会提示 bad connect，如下：

    14/12/21 17:02:26 INFO hdfs.DFSClient: Exception in createBlockOutputStream
    java.io.IOException: Bad connect ack with firstBadLink as 10.10.12.168:50010

这个和上面是同一个原因，是对应的datanode被关闭导致的。但是是什么原因导致的关闭呢？datanode日志报错:

发现有161上如下错误：

参考 [hadoop的datanode异常结束](http://blog.csdn.net/joomlaer/article/details/16801717){:target="_blank"}，是因为有坏的磁盘导致的。
可在在hdfs-site.xml里屏蔽掉坏磁盘。  
如何检测坏的磁盘， `hadoop fsck /` 可以么？

参考别的资料，配置 hdfs-site.xml 中的 `dfs.datanode.socket.write.timeout`，尝试将timeout的时间调长些。
