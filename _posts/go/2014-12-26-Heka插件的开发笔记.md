---
title:  Heka插件的开发笔记
date: 2014-12-26 18:12:28 +0800
tags: go
- a
- b
---

* toc 
{:toc}

##背景

Push 想实现精准推送的功能，这就需要统计的数据来实现。而之前的日志格式和统一后的日志格式不兼容，为此做一个格式转化功能：将Json格式转为 `^B` 分隔的日志。 
在转的过程中，Heka与Redis结合，实现实时统计的功能，并将转化好之后的日志落地。  
本文中的插件的开发使用go语言。

##基本规则

实现一个插件，首先是一些基本的初始化操作，再有需要实现几个基本的接口，即配置方面操作和注册操作。

###初始化操作
Heka插件接口定义了初始化的操作，如下：

    type Plugin interface {
        Init(config interface{}) error
    }
    
例如一个最简单的例子，我们实现一个 `SimpleOutput` 的插件，初始化时，不需要做任何工作，则可以如下：
    
    type SimpleOutput struct {
    }
    
    func (this *Push2KpOutput) Init(config interface{}) (err error) {
        return
    }

###关于配置

从[官网文档](https://hekad.readthedocs.org/en/latest/developing/plugin.html){:target="_blank"} 的 Custom Plugin Config Structs 知道，
`HasConfigStruct`接口只有 `ConfigStruct` 的方法。假设一个简单的插件，不需要指定任何的配置，则如下

    type SimpleOutputConfig struct {
    }
    
    func (this *SimpleOutput) ConfigStruct() interface{} {
        return &SimpleOutputConfig{}
    }

###注册
关于功能实现的部分后面在作介绍。在使用该插件前还有步重要的操作，即注册该插件。开始没有注册时，曾遇到提示

    No registered plugin type: SimpleOutput

而注册插件只需要调用RegisterPlugin方法即可，官网也推荐在init函数中实现，即如下：

    func init() {
        RegisterPlugin("SimpleOutput", func() interface{} {
            return new(SimpleOutput)
        })
    }

###补充

此处说明的是对插件的开发中的一些过程，[Heka使用学习](http://blog.woshifengzi.com/2014/12/09/Heka%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0.html)中的 `添加插件`部分的说明，更应该最开始的第一步操作。  

    $ cmake/plugin_loader.cmake
    add_external_plugin(svn https://url_to/heka_plugins/simple:local)
    
    $ ls externals/simple/simple_output.go
    
要新增加的插件在配置的目录下。

测试时还有一点浪费了一些时间，即配置文件中output的MessageMatcher先设成TRUE，让第一步的测试能看到结果，

    [Simple_output]
    type = "SimpleOutput"
    message_matcher = "TRUE"
    
    
##logstreamer_input过程

heka提供了很多的插件样例，而了解了其中一个，也就可以融汇贯通，了解其他样例，开发新的插件也就没有什么问题了。  
在实际开发的过程中使用了logstreamer的例子，此处即是此插件的一些笔记。

###配置、结构体部分

看每个结构体中定义的变量，了解这些变量的用途以及必要性。  
LogstreamerInputConfig结构体的内容，确定每

    生成日志文件信息对象使用，hekad/config.go定义，HekadConfig结构体变量
    Hostname string 
    
    存放日志的基本路径
    LogDirectory  `toml:"log_directory"`
    
    存放Heka处理过程的路径，如处理到哪个文件的seek是多少了
    JournalDirectory
    
    文件名称匹配，如file_match = '(?P<Year>\d{4})(?P<Month>\d{2})/(?P<Day>\d{2})/(?P<Hour>\d{2})/\w+_\d{10}\.log'
    FileMatch `toml:"file_match"`
    
    文件匹配时的优先级，如 priority = ["Year", "Month", "Day", "Hour"]，就会按照我们设定的年月日时先后顺序读取文件
    Priority []string
    
    分开不同结果。比如源头有两种游戏，gameA、gameB，希望生成不同的名称，differentiator = ["gameA"]
    Differentiator []string
    
    对于接受到的日志，会有些日志认为太旧就过滤掉了。使用OldestDuration来限定过滤规则
    OldestDuration string `toml:"oldest_duration"`
    
    多久扫描一次，如有新的日志就继续前进
    RescanInterval 
    
    得到日志使用解码
    Decoder
    
    将日志文件分解为message所用到的格式，常用 message.proto
    ParserType
    
    指定日志所用的分隔符，如 '\n'
    Delimiter
    
    指定分隔符的位置，是开头还是结尾
    DelimiterLocation
    
    如果日志超过buffer的大小会截断，这些截断的是否丢弃
    KeepTruncatedMessages
    
    
上面是关于配置文件所用变量的定义，插件类（LogstreamerInput）本身也有一些变量，如
        
    // 封装整个heka/pipeline配置的主要对象 pipeline/config.go中定义，
    pConfig      *p.PipelineConfig  
    
    // 关于log流的集合，logstreamer/filehandling.go中定义
    // 定义有rescanInterval/oldestDuration/logstreams
    logstreamSet *ls.LogstreamSet

    logstreamSetLock sync.RWMutex
    
    rescanInterval   time.Duration
    
    // 在一个配置文件中，可能会在多个地方使用这个插件，所以用一个map来存放
    plugins   map[string]*LogstreamInput
    
    // 看到[]chan chan bool 这个类型，先就蒙了
    // channel是原生值，即可以通过channel发送
    // 定义个渠道的数组，里面传递也是渠道，而这些里面的渠道传递的是bool
    // 因为plugins中可能有多个，所以stop的信息也就有多个了  --> 还有疑问
    stopLogstreamChans  []chan chan bool
    
    // ??
    stopChan        chan bool
    
    // 解码名称
    decoderName     string
    // 处理
    parser              string
    
    // 关于分隔符的信息
    delimiter           string
    delimiterLocation   string 
    
    hostName            string
    pluginName      string
    keepTruncatedMessages       bool
    
Init函数基本就是初始化或配置上面的这些变量了

### 运行
LogstreamerInput 插件的主要功能是将日志流的入端，日志都按照一定的命名规则按照文件来存放。
所以该插件会扫描这件日志文件，当有满足条件的日志到来时，就会导成流进入到Heka的处理过程中。

此过程的几个知识点

* 扫描日志文件顺序
按照我们配置所指定的优先级先后扫面日志文件，而且处理每个日志文件时都会记录偏移量，保证不重复，且利于日志的追加。  
例子可参考上面代码中 年月日时，`priority = ["Year", "Month", "Day", "Hour"]`。  
这些优先级是如何实现的，使用了heka的机制。

* 定时扫描
直接看一段扫描处理过程的简要代码，即可明白。

    rescan := time.Tick(li.rescanInterval)
    for ok {
        select {
            case <-li.stopChan:
                ok = false
                ... 
                close(li.stopChan)
            case <-rescan:
                li.logstreamSetLock.Lock()
                ...
                li.logstreamSetLock.Unlock() 
        }
    }
    
 这个过程中 stopChan的数据（信号）是如何得到的呢？使用了Heka默认的 `Stop`函数

    func (li *LogstreamerInput) Stop() {
        li.stopChan <- true
        <-li.stopChan
    }

* 扫描
    
    扫描实际上用的是`LogstreamInput`的 Run方法！
    <待继续研究！>
    
## 其他插件

###decoder
例如将一个json格式的数据转为以 `^B` 分隔的日志，可使用decoder的插件来实现，大体过程如下：

    // Heka will call this to give us access to the runner.
    func (mj *MJPushDecoder) SetDecoderRunner(dr DecoderRunner) {
        mj.dRunner = dr
    }
    
    // 此处定义json的格式
    type BodyInfo struct {
        。。。
    }
    type PushMessage struct {
        Event_id int
        Body     BodyInfo
    }
    
    func (mj *MJPushDecoder) Decode(pack *PipelinePack) (packs []*PipelinePack, err error) {
        // 做json解析
        pushMessage := PushMessage{}
        e = json.Unmarshal([]byte(*pack.Message.Payload), &pushMessage)
        if  e != nil {
            fmt.Println(err)
            return
        }
    
        var bf bytes.Buffer
        bf.WriteString(time.Unix(int64(server_time),0).Format("2006-01-02T15:04:05+08:00"))
        bf.WriteByte('\x02')
        // 1 : IP
        bf.WriteString(pushMessage.Body.Ip)
        ....
        bf.WriteByte('\n')  // 配置接收端的encoder时， append_newlines = false

        newPayload := bf.String()
        pack.Message.Payload = &newPayload
        
        packs = []*PipelinePack{pack}
        return
    }
    func init() { ... }// 注册
    
    
注意，decoder得到的pack不需要调用 `pack.Recycle()`！

###encoder
在实现的代码中，encoder与decoder非常的相似，就不在提供代码！

###output

我们在使用output时，用到了两种类型，一是参考 `file_logstreamer_output` 插件的方式，将heka流出的数据落入到指定路径、命名下的文件中；一是使用Redis做一些实时计算！  
前者的具体代码与logstreamer_output很近，但是添加了两点:  
* 根据接受到的日志时间，落到对应的 年月日时的文件中，即 yyyymm/dd/hh/xxx_yyyymmddhh.log
* 为了与其他代码兼容，在某日志文件10分钟没有日志流入时，生成一个 yyyymm/dd/hh.done 的文件，表示该时段的日志接受完成。


使用redis做计算的代码大体如下：

    import (
        ...
        "github.com/garyburd/redigo/redis"
    )
    func init() { ... } // 注册
    type RedisOutput struct {
        RedisPool        *redis.Pool
        redisServer      string
        redisPassword    string
        redisMaxIdle     int 
        redisIdleTimeout int 
        ...
    }
    func (o *RedisOutput) ConfigStruct() interface{} { ... } // 默认的构造函数
    
    func (o *KptjHistoryRedisOutput) initPool() (err error) {
    o.RedisPool = &redis.Pool{
        MaxIdle:     o.redisMaxIdle,
        IdleTimeout: time.Duration(o.redisIdleTimeout) * time.Second,
        Dial: func() (redis.Conn, error) {
            c, err := redis.Dial("tcp", o.redisServer)
            if err != nil {
                return nil, err
            }
            if _, err := c.Do("AUTH", o.redisPassword); err != nil {
                c.Close()
                return nil, err
            }
            return c, err
        },
        TestOnBorrow: func(c redis.Conn, t time.Time) error {
            _, err := c.Do("PING")
            return err
        },
    }

    // test connection
    conn := o.RedisPool.Get()
    if _, err = conn.Do("PING"); err != nil {
        return
    }
    conn.Close()
    return
    }
    func (o *RedisOutput) Init(config interface{}) (err error) { ... }
    
    func (this *RedisOutput) Run(or OutputRunner, h PluginHelper) (err error) {
        inChan := or.InChan()
    ok := true
     for ok {
        select {
        case pack, ok = <-inChan:
            if !ok {
                break
            }
            conn := this.RedisPool.Get()
                        ...  // 相应的redis操作  如  conn.Send("INCR", allUuidNewKey)
                        conn.Close()
                } // select
        } // end of for
        return
    }
    
注： 可使用 `conn.Send("MULTI")`  `...`  `conn.Do("EXEC")` 来保证redis操作的原子性！

## 后续计划

阅读Heka的源代码，从 `cmd/hekad/main.go`做入口，既能更深入了解heka，也能好好的学习go语言！！

    
